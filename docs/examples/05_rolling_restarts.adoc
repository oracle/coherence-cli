///////////////////////////////////////////////////////////////////////////////

    Copyright (c) 2021, 2023 Oracle and/or its affiliates.
    Licensed under the Universal Permissive License v 1.0 as shown at
    https://oss.oracle.com/licenses/upl.

///////////////////////////////////////////////////////////////////////////////

= Rolling Restarts

== Rolling Restarts

=== Overview

This example walks you through how to monitor the High Available (HA) Status or `StatusHA`
value for Coherence Partitioned Services within a cluster by using the `cohctl get services` command.

`StatusHA` is most commonly used to ensure services are in a
safe state between restarting cache servers during a rolling restart.

=== Setup for this Example

In this example we have a cluster called `my-cluster` with the following setup:

1. A single storage-disabled management node running Management over REST enabled
2. 2 storage-enabled nodes on `machine1`
3. 2 storage-enabled nodes on `machine2`
4. 2 storage-enabled nodes on `machine3`
5. A Coherence console client running

=== Run the example

In this example we will carry out a rolling restart of our cluster to simulate applying an application code patch to
our cluster. For more details on rolling restarts, please see {commercial-docs-base-url}/develop-applications/starting-and-stopping-cluster-members.html[Starting and Stopping Cluster Members] in the Coherence documentation.

The process will be:

1. Stop member 1 on first machine
2. Wait for NODE-SAFE - (Can't get to MACHINE-SAFE because of unbalanced partition counts between machines)
3. Stop member 2 on first machine
4. Wait for MACHINE-SAFE - When they could apply an application patch to our first machine.
5. Start member 1 and 2 on first machine
6. Wait for MACHINE-SAFE
7. Repeat steps 1-6 on second and third machines

Read on below for the example.

==== 1. Show the clusters

[source,bash]
----
cohctl get clusters
----
Output:
[source,bash]
----
CONNECTION  TYPE  URL                                                  VERSION  CLUSTER NAME  CLUSTER TYPE  LOCAL
local       http  http://localhost:30000/management/coherence/cluster  23.03    my-cluster    Standalone    false
----

[source,bash]
----
cohctl set context local
----
Output:
[source,bash]
----
Current context is now local
----

==== 2. Get the members

[source,bash]
----
cohctl get members -o wide -m
----
Output:
[source,bash]
----
Using cluster connection 'local' from current context.

Cluster Heap - Total: 6.750GB, Used: 1.076GB, Available: 5.674GB (84.1%)

NODE ID  ADDRESS          PORT  PROCESS  MEMBER  ROLE              MACHINE   RACK  SITE  PUBLISHER  RECEIVER  MAX HEAP  USED HEAP  AVAIL HEAP
      1  /192.168.1.124  58374    42988  n/a     Management        n/a       n/a   n/a       0.995     1.000    512 MB      53 MB      459 MB
      2  /192.168.1.124  58389    43011  n/a     CoherenceServer   machine1  n/a   n/a       1.000     1.000   1024 MB     307 MB      717 MB
      3  /192.168.1.124  58399    43033  n/a     CoherenceServer   machine1  n/a   n/a       0.997     1.000   1024 MB     140 MB      884 MB
      4  /192.168.1.124  58434    43055  n/a     CoherenceServer   machine2  n/a   n/a       0.997     1.000   1024 MB     175 MB      849 MB
      5  /192.168.1.124  58464    43081  n/a     CoherenceServer   machine2  n/a   n/a       0.997     1.000   1024 MB     184 MB      840 MB
      7  /192.168.1.124  58774    44276  n/a     CoherenceServer   machine3  n/a   n/a       1.000     1.000   1024 MB     124 MB      900 MB
      8  /192.168.1.124  58808    44473  n/a     CoherenceServer   machine3  n/a   n/a       1.000     1.000   1024 MB      97 MB      927 MB
      9  /192.168.1.124  58868    44523  n/a     CoherenceConsole  n/a       n/a   n/a       1.000     1.000    256 M       22 MB      234 MB
----

NOTE: We can see the management node on Node 1, the storage members on nodes 2-5 and the console on node 6.

==== 3. Get the partitioned services

[source,bash]
----
cohctl get services -t DistributedCache -o wide
----
Output:
[source,bash]
----
Using cluster connection 'local' from current context.

SERVICE NAME       TYPE              MEMBERS  STATUS HA     STORAGE  PARTITIONS  ENDANGERED  VULNERABLE  UNBALANCED  STATUS
PartitionedTopic   DistributedCache        7  MACHINE-SAFE        6         257           0           0           0  Safe
PartitionedCache2  DistributedCache        7  MACHINE-SAFE        6         257           0           0           0  Safe
PartitionedCache   DistributedCache        7  MACHINE-SAFE        6         257           0           0           0  Safe
----

See below for explanations of the above columns:

* STATUS HA - The High Availability (HA) status for this service. A value of MACHINE-SAFE indicates that all the cluster members running on any given computer could be stopped without data loss. A value of NODE-SAFE indicates that a cluster member could be stopped without data loss. A value of ENDANGERED indicates that abnormal termination of any cluster member that runs this service may cause data loss. A value of N/A indicates that the service has no high availability impact.
* STORAGE - Specifies the total number of cluster members running this service for which local storage is enabled
* PARTITIONS - The total number of partitions that every cache storage is divided into
* ENDANGERED - The total number of partitions that are not currently backed up
* VULNERABLE - The total number of partitions that are backed up on the same machine where the primary partition owner resides
* UNBALANCED - The total number of primary and backup partitions that remain to be transferred until the partition distribution across the storage enabled service members is fully balanced

==== 4. View the caches

In our case we have the following caches defined:

[source,bash]
----
cohctl get caches -m
----
Output:
[source,bash]
----
Using cluster connection 'local' from current context.

Total Caches: 3, Total primary storage: 175MB

SERVICE            CACHE      COUNT    SIZE
PartitionedCache   tim        1,000    9 MB
PartitionedCache2  test-1   100,000  110 MB
PartitionedCache2  test-2    50,000   55 MB
----

NOTE: You can use the `-o wide` to display more information.

==== 5. Start watching the services

[source,bash]
----
cohctl get services -t DistributedCache -w -o wide
----

NOTE: The above will continue watching the services. Keep this open in a separate terminal.

==== 6. Carry out a rolling restart of the cluster.

With the above command running in a separate terminal, carry out the following for each machine and watch for the StatusHA values.

1. Stop member 1 on first machine
2. Wait for NODE-SAFE - When stopping the first cache server, you may observe the service StatusHA go to ENDANGERED straight after Coherence detects the failure and starts the rebalancing. When the StatusHA returns to NODE-SAFE, and unbalanced partitions are zero, you can continue.
3. Stop member 2 on first machine
4. Wait for MACHINE-SAFE - We will pretend to apply the software patch.
5. Start member 1 and 2 on first machine
6. Wait for MACHINE-SAFE
7. Repeat steps 1-6 on second and third machines

=== Scripting the Rolling Redeploy

The Coherence CLI cannot directly start or stop members, but can be use in scripts to detect when services have reached a certain state.

You can use the `-a MACHINE-SAFE` option of `get services` to wait up to the timeout value (default to 60 seconds), for the StatusHA
to be equal or greater that the value you specified. If it reaches this value in the timeout, the command will return 0 exit code but if
it does not, then a return code of 1 is returned.

The following example would wait up to 60 seconds for DistributedCache services to be MACHINE-SAFE.

[source,bash]
----
cohctl get services -t DistributedCache -w -a MACHINE-SAFE
----

== See Also

* <<docs/reference/20_services.adoc,Services>>
* {commercial-docs-base-url}/develop-applications/starting-and-stopping-cluster-members.html[Starting and Stopping Cluster Members]
* {commercial-docs-base-url}/manage/oracle-coherence-mbeans-reference.html[Coherence MBean Reference]